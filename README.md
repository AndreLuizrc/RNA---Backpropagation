# ğŸ§  Projeto â€” ImplementaÃ§Ã£o de Redes Neurais com Backpropagation

Este projeto consiste na implementaÃ§Ã£o, do zero, de uma **rede neural artificial treinada atravÃ©s do algoritmo de Backpropagation**, com suporte para diferentes funÃ§Ãµes de ativaÃ§Ã£o, nÃºmero de camadas intermediarias e hiperparÃ¢metros customizÃ¡veis.

O objetivo Ã© demonstrar de forma prÃ¡tica como redes neurais funcionam internamente, aplicando o algoritmo de retropropagaÃ§Ã£o para ajuste de pesos e resoluÃ§Ã£o de problemas clÃ¡ssicos como **AND, OR e XOR**.

---

## ğŸš€ Funcionalidades Principais
- âœ… Suporte para mÃºltiplas camadas intermediarias (rede profunda).
- âœ… ImplementaÃ§Ã£o completa do algoritmo de **Backpropagation**.
- âœ… Escolha dinÃ¢mica da **funÃ§Ã£o de ativaÃ§Ã£o** (`Sigmoid` e `Tanh`).
- âœ… InicializaÃ§Ã£o aleatÃ³ria dos pesos e bias.
- âœ… Treinamento no modo **Batch** (atualizaÃ§Ã£o dos pesos apÃ³s processar todas as amostras de uma Ã©poca).
- âœ… PrediÃ§Ã£o de saÃ­das apÃ³s o treinamento.
- âœ… RelatÃ³rios dos erros por Ã©poca (console).
- âœ… FÃ¡cil expansÃ£o e modificaÃ§Ã£o.

---

## ğŸ—ï¸ Arquitetura da Rede Neural
- Camada de entrada
- Uma ou mais **camadas intermediarias**
- Camada de saÃ­da

---

## ğŸ“œ Como Funciona o Backpropagation?
1. **Forward Pass:**  
   - PropagaÃ§Ã£o dos dados de entrada atÃ© a saÃ­da da rede, passando por todas as camadas.  
   - A saÃ­da linear de cada neurÃ´nio Ã© processada pela funÃ§Ã£o de ativaÃ§Ã£o, cuja saÃ­da alimenta a camada seguinte.

2. **Backward Pass (Backpropagation):**  
   - CÃ¡lculo do erro na camada de saÃ­da (diferenÃ§a entre saÃ­da esperada e saÃ­da obtida).  
   - O erro Ã© retropropagado pelas camadas intermediarias, ajustando os pesos proporcionalmente ao erro e Ã  derivada da funÃ§Ã£o de ativaÃ§Ã£o.

3. **AtualizaÃ§Ã£o dos Pesos e Bias:**  
   - Realizada apÃ³s o processamento de todas as amostras de uma Ã©poca.  
   - Leva em conta a **taxa de aprendizado**, o erro e as ativaÃ§Ãµes.

---

## ğŸ”§ HiperparÃ¢metros configurÃ¡veis
- NÃºmero de camadas intermediarias e neurÃ´nios por camada.
- FunÃ§Ã£o de ativaÃ§Ã£o (`sigmoid` ou `tanh`).
- Taxa de aprendizado (`learning_rate`).
- NÃºmero de Ã©pocas (`epochs`).

---

## ğŸ§  FunÃ§Ãµes de AtivaÃ§Ã£o Implementadas

| FunÃ§Ã£o        | Intervalo de saÃ­da | CaracterÃ­sticas                                   |
|----------------|---------------------|---------------------------------------------------|
| **Sigmoid**    | (0, 1)              | Pode sofrer com vanishing gradient, nÃ£o centrada. |
| **Tanh**       | (-1, 1)             | Centragem em zero, melhora aprendizagem em XOR.  |

---

## ğŸ ImportÃ¢ncia dos Componentes da Rede Neural

### âœ”ï¸ Bias
Permite que o neurÃ´nio **desloque a funÃ§Ã£o de ativaÃ§Ã£o**, garantindo que ela **nÃ£o seja restrita a passar pela origem (0,0)**. Isso oferece maior flexibilidade ao modelo, permitindo ajustes mais precisos, independentemente dos valores de entrada.

### âœ”ï¸ Taxa de Aprendizado
Controla o **tamanho dos ajustes dos pesos durante cada iteraÃ§Ã£o**.  
- Valor alto â†’ pode fazer o modelo divergir ou ultrapassar o mÃ­nimo.  
- Valor muito baixo â†’ treinamento extremamente lento.  
- Um valor bem ajustado permite aprendizagem estÃ¡vel e eficiente.

### âœ”ï¸ FunÃ§Ã£o de AtivaÃ§Ã£o
Introduz **nÃ£o linearidade**, permitindo que a rede aprenda padrÃµes complexos e resolva problemas nÃ£o linearmente separÃ¡veis.  
Sem uma funÃ§Ã£o de ativaÃ§Ã£o, a rede se comportaria como uma simples regressÃ£o linear, independentemente da profundidade.

---

